{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-10T11:25:06.398887Z"
    }
   },
   "source": [
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# -------------------------------\n",
    "# 配置\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "input_file = \"data/hendrycks_math_train.json\"\n",
    "acc_file = \"output/deepseek-r1-1.5b-generated-predictions-detailed-results.jsonl\"\n",
    "output_file = \"z_score/deepseek-r1-1.5b_ppl_conf_acc_z_scores_results.json\"\n",
    "\n",
    "# 模型统计量\n",
    "model_stats = {\n",
    "    \"ppl_mean\": 9.795982360839844,\n",
    "    \"ppl_std\": 22.284496307373047,\n",
    "    \"conf_mean\": 0.6799513101577759,\n",
    "    \"conf_std\": 0.08082679659128189\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 加载模型和 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\").eval()\n",
    "\n",
    "# -------------------------------\n",
    "# 加载数据\n",
    "with open(input_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(acc_file, \"r\") as f:\n",
    "    acc_data = [json.loads(line) for line in f]\n",
    "\n",
    "assert len(data) == len(acc_data), \"样本数量不匹配\"\n",
    "\n",
    "# -------------------------------\n",
    "# 计算 PPL 和 Confidence\n",
    "def compute_ppl_and_conf(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"mps\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        ppl = math.exp(loss.item())\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        max_probs = probs.max(dim=-1).values\n",
    "        conf = max_probs[0, 1:-1].mean().item()  # exclude BOS & EOS\n",
    "\n",
    "    return ppl, conf\n",
    "\n",
    "# -------------------------------\n",
    "# 批量处理\n",
    "results = []\n",
    "for sample, acc_record in tqdm(zip(data, acc_data), total=len(data)):\n",
    "    input_text = sample[\"input\"]\n",
    "    acc = 1 if acc_record.get(\"accuracy\", 0.0) >= 99.9 else 0\n",
    "\n",
    "\n",
    "    try:\n",
    "        ppl, conf = compute_ppl_and_conf(input_text)\n",
    "        z_ppl = (ppl - model_stats[\"ppl_mean\"]) / model_stats[\"ppl_std\"]\n",
    "        z_conf = (conf - model_stats[\"conf_mean\"]) / model_stats[\"conf_std\"]\n",
    "        results.append({\n",
    "            \"z_ppl\": z_ppl,\n",
    "            \"z_conf\": z_conf,\n",
    "            \"acc\": acc\n",
    "        })\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"error\": str(e),\n",
    "            \"acc\": acc\n",
    "        })\n",
    "\n",
    "# -------------------------------\n",
    "# 保存结果\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"✅ 完成，已保存到: {output_file}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7c8b59cbd3ff550"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
